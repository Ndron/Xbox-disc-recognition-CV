{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"fifa19.png\", 0) # 0 = cv2.IMREAD_GRAYSCALE  0 for gray image\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "kp_image, desc_image = sift.detectAndCompute(img, None)  # instade of None you can add mask\n",
    "\n",
    "img = cv2.drawKeypoints(img,kp_image,img)                                                 ##query image\n",
    "\n",
    "#Start feature matching\n",
    "index_params = dict(algorithm=0, trees=5)\n",
    "search_params = dict()\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    grayframe = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # make video frame gray too   ## train image\n",
    "    \n",
    "    kp_grayframe, desc_grayframe = sift.detectAndCompute(grayframe, None)  # key points and deskriptor\n",
    "    grayframe = cv2.drawKeypoints(grayframe,kp_grayframe,grayframe)  # plot keypoints on a frame\n",
    "    \n",
    "    #feature matching\n",
    "    matches=flann.knnMatch(desc_image,desc_grayframe,k=2)\n",
    "    \n",
    "    good_points=[]\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.5*n.distance:\n",
    "            good_points.append(m)\n",
    "    \n",
    "    img3 = cv2.drawMatches(img, kp_image, grayframe, kp_grayframe, good_points, grayframe)   # A to see knn match\n",
    "    \n",
    "    #Homografy for matching\n",
    "    \n",
    "    try:\n",
    "        if len(good_points) > 5:\n",
    "            query_pts = np.float32([kp_image[m.queryIdx].pt for m in good_points]).reshape(-1, 1, 2)\n",
    "            train_pts = np.float32([kp_grayframe[m.trainIdx].pt for m in good_points]).reshape(-1, 1, 2)\n",
    " \n",
    "            matrix, mask = cv2.findHomography(query_pts, train_pts, cv2.RANSAC, 5.0)\n",
    "            matches_mask = mask.ravel().tolist()\n",
    "        \n",
    "            # Perspective transform\n",
    "            #h, w = img.shape\n",
    "            #pts = np.float32([[0, 0], [0, h], [w, h], [w, 0]]).reshape(-1, 1, 2)\n",
    "        \n",
    "            #dst = cv2.perspectiveTransform(pts, matrix)\n",
    " \n",
    "            #homography = cv2.polylines(frame, [np.int32(dst)], True, (255, 0, 0), 3)    # 255 рисум синий\n",
    "            # рисум на картинке\n",
    "            #font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            #cv2.putText(homography,'OpenCV',(10,500), font, 4,(255,255,255),2,cv2.LINE_AA)\n",
    "    \n",
    "            #cv2.imshow(\"Homography\", homography)\n",
    "        #else:\n",
    "            #cv2.imshow(\"Homography\", grayframe)\n",
    "    \n",
    "        #cv2.imshow(\"Image\", img)\n",
    "        #cv2.imshow(\"Frame\", grayframe)\n",
    "        cv2.imshow(\"compared\", img3)                                                             # A to see knn match\n",
    "    \n",
    "        k = cv2.waitKey(30) & 0xFF\n",
    "        if k == 27:\n",
    "            break\n",
    "    except:\n",
    "        print ('Restarting!')\n",
    "        continue\n",
    "            \n",
    "            \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can replace it with color_frame from construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Configure depth and color streams\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "\n",
    "# Start streaming\n",
    "pipeline.start(config)\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "\n",
    "        # Wait for a coherent pair of frames: depth and color\n",
    "        frames = pipeline.wait_for_frames()\n",
    "        depth_frame = frames.get_depth_frame()\n",
    "        color_frame = frames.get_color_frame()\n",
    "        if not depth_frame or not color_frame:\n",
    "            continue\n",
    "\n",
    "        # Convert images to numpy arrays\n",
    "        depth_image = np.asanyarray(depth_frame.get_data())\n",
    "        color_image = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "        # Apply colormap on depth image (image must be converted to 8-bit per pixel first)\n",
    "        depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    "\n",
    "        # Stack both images horizontally\n",
    "        images = np.hstack((color_image, depth_colormap))\n",
    "\n",
    "        # Show images\n",
    "        cv2.namedWindow('RealSense', cv2.WINDOW_AUTOSIZE)\n",
    "        cv2.imshow('RealSense', images)                      # replace with color_image or depth_colormap\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "finally:\n",
    "\n",
    "    # Stop streaming\n",
    "    pipeline.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
